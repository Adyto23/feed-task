{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86d2647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Date Text\n",
      "0  Sat 01 Jul 2023, 16:00\\n\\t\\t\\t\\t Chamber Music...\n",
      "1   Sun 02 Jul 2023, 16:00\\n\\t\\t\\t\\t Main Auditorium\n",
      "2   Sun 02 Jul 2023, 20:00\\n\\t\\t\\t\\t Main Auditorium\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.berliner-philharmoniker.de/en/concerts/calendar\"  # Replace with the actual URL\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all the elements containing the date using the CSS selector\n",
    "    date_elements = soup.select(\"p.time-and-place.font-icon.dot.color-coded\")\n",
    "\n",
    "    # Initialize a list to store the extracted date texts\n",
    "    date_texts = []\n",
    "\n",
    "    # Extract the text from each element\n",
    "    for element in date_elements:\n",
    "        date_text = element.get_text().strip()\n",
    "        date_texts.append(date_text)\n",
    "\n",
    "    # Create a DataFrame to store the data\n",
    "    df = pd.DataFrame({\"Date Text\": date_texts})\n",
    "\n",
    "    # Print or use the DataFrame as needed\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to fetch the URL:\", url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56f2361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Members of the Rundfunkchor Berlin, Seongju Oh, Juae Ha\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.berliner-philharmoniker.de/en/concerts/calendar\"  # Replace with the actual URL\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the specific element containing the data using CSS selector\n",
    "    description_element = soup.select(\"body > div.main-wrapper.en > main > section > section:nth-child(1) > article:nth-child(2) > div > div.description.performance-content > p.description-text\")\n",
    "\n",
    "    if description_element:\n",
    "        # Extract the text from the element (the description)\n",
    "        description_text = description_element[0].get_text().strip()\n",
    "\n",
    "        # Print or use the extracted description as needed\n",
    "        print(\"Description:\", description_text)\n",
    "    else:\n",
    "        print(\"Element with the specified CSS selector not found.\")\n",
    "else:\n",
    "    print(\"Failed to fetch the URL:\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ae59e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Text</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat 01 Jul 2023, 16:00\\n\\t\\t\\t\\t Chamber Music...</td>\n",
       "      <td>Members of the Rundfunkchor Berlin, Seongju Oh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun 02 Jul 2023, 16:00\\n\\t\\t\\t\\t Main Auditorium</td>\n",
       "      <td>Rundfunkchor Berlin und Gäste, Rundfunk-Sinfon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun 02 Jul 2023, 20:00\\n\\t\\t\\t\\t Main Auditorium</td>\n",
       "      <td>Sinfonieorchester des Collegium Musicum Berlin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Date Text  \\\n",
       "0  Sat 01 Jul 2023, 16:00\\n\\t\\t\\t\\t Chamber Music...   \n",
       "1   Sun 02 Jul 2023, 16:00\\n\\t\\t\\t\\t Main Auditorium   \n",
       "2   Sun 02 Jul 2023, 20:00\\n\\t\\t\\t\\t Main Auditorium   \n",
       "\n",
       "                                         Description  \n",
       "0  Members of the Rundfunkchor Berlin, Seongju Oh...  \n",
       "1  Rundfunkchor Berlin und Gäste, Rundfunk-Sinfon...  \n",
       "2  Sinfonieorchester des Collegium Musicum Berlin...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d385b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: Sun\n",
      "Date: 02 Jul\n",
      "Location: 16:00 Main Auditorium\n"
     ]
    }
   ],
   "source": [
    "# Given string\n",
    "input_string = df['Date Text'][1]\n",
    "\n",
    "# Split the string by newline and whitespace characters\n",
    "split_string = input_string.split()\n",
    "\n",
    "# Extracting day, date, and location\n",
    "day = split_string[0]\n",
    "date = split_string[1] + ' ' + split_string[2]\n",
    "location = ' '.join(split_string[4:])\n",
    "\n",
    "print(\"Day:\", day)\n",
    "print(\"Date:\", date)\n",
    "print(\"Location:\", location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f05c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date and Time            Location  \\\n",
      "0  01 Jul 2023, 16:00  Chamber Music Hall   \n",
      "1  02 Jul 2023, 16:00     Main Auditorium   \n",
      "2  02 Jul 2023, 20:00     Main Auditorium   \n",
      "\n",
      "                                         Description  \n",
      "0  Members of the Rundfunkchor Berlin, Seongju Oh...  \n",
      "1  Rundfunkchor Berlin und Gäste, Rundfunk-Sinfon...  \n",
      "2  Sinfonieorchester des Collegium Musicum Berlin...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.berliner-philharmoniker.de/en/concerts/calendar\"  # Replace with the actual URL\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all performance details containers\n",
    "    performance_containers = soup.select(\"div.basic-details\")\n",
    "\n",
    "    # Initialize a list to store the extracted data\n",
    "    all_data = []\n",
    "\n",
    "    # Loop through each performance container\n",
    "    for container in performance_containers:\n",
    "        # Extract date and time\n",
    "        date_time_elem = container.select_one(\"div.performance-date p.date-and-time\")\n",
    "        date_time = date_time_elem.get_text(strip=True)\n",
    "\n",
    "        # Extract location\n",
    "        location_elem = container.select_one(\"div.performance-place p\")\n",
    "        location = location_elem.get_text(strip=True)\n",
    "\n",
    "        # Find the corresponding description container for the current performance\n",
    "        description_container = container.find_next_sibling(\"div\", class_=\"description\")\n",
    "\n",
    "        # Extract the description text\n",
    "        description_elem = description_container.select_one(\"p.description-text\")\n",
    "        description = description_elem.get_text(strip=True)\n",
    "\n",
    "        # Create a dictionary with the extracted data for this performance\n",
    "        performance_data = {\n",
    "            \"Date and Time\": date_time,\n",
    "            \"Location\": location,\n",
    "            \"Description\": description\n",
    "        }\n",
    "\n",
    "        # Append the data for this performance to the main list\n",
    "        all_data.append(performance_data)\n",
    "\n",
    "    # Create a DataFrame to store all the data\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Print or use the DataFrame as needed\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to fetch the URL:\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b186201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date and Time</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 Jul 2023, 16:00</td>\n",
       "      <td>Chamber Music Hall</td>\n",
       "      <td>Members of the Rundfunkchor Berlin, Seongju Oh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02 Jul 2023, 16:00</td>\n",
       "      <td>Main Auditorium</td>\n",
       "      <td>Rundfunkchor Berlin und Gäste, Rundfunk-Sinfon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02 Jul 2023, 20:00</td>\n",
       "      <td>Main Auditorium</td>\n",
       "      <td>Sinfonieorchester des Collegium Musicum Berlin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date and Time            Location  \\\n",
       "0  01 Jul 2023, 16:00  Chamber Music Hall   \n",
       "1  02 Jul 2023, 16:00     Main Auditorium   \n",
       "2  02 Jul 2023, 20:00     Main Auditorium   \n",
       "\n",
       "                                         Description  \n",
       "0  Members of the Rundfunkchor Berlin, Seongju Oh...  \n",
       "1  Rundfunkchor Berlin und Gäste, Rundfunk-Sinfon...  \n",
       "2  Sinfonieorchester des Collegium Musicum Berlin...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44d24c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.berliner-philharmoniker.de/en/concerts/calendar\"  # Replace with the actual URL\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all month divider sections\n",
    "    month_dividers = soup.select(\"section.calendar-section header h2.month-title\")\n",
    "\n",
    "    # Initialize a list to store all concert data\n",
    "    all_data = []\n",
    "\n",
    "    # Loop through each month divider section\n",
    "    for divider in month_dividers:\n",
    "        # Extract the month name from the divider section\n",
    "        month_name = divider.get_text(strip=True)\n",
    "\n",
    "        # Find all performance details containers within this month\n",
    "        month_performance_containers = divider.find_next(\"div\", class_=\"basic-details\").find_all_next(\"div\", class_=\"basic-details\", limit=None)\n",
    "\n",
    "        # Loop through each performance container within this month\n",
    "        for container in month_performance_containers:\n",
    "            # Extract date and time\n",
    "            date_time_elem = container.select_one(\"div.performance-date p.date-and-time\")\n",
    "            date_time = date_time_elem.get_text(strip=True)\n",
    "\n",
    "            # Extract location\n",
    "            location_elem = container.select_one(\"div.performance-place p\")\n",
    "            location = location_elem.get_text(strip=True)\n",
    "\n",
    "            # Find the corresponding description container for the current performance\n",
    "            description_container = container.find_next_sibling(\"div\", class_=\"description\")\n",
    "\n",
    "            # Extract the description text\n",
    "            description_elem = description_container.select_one(\"p.description-text\")\n",
    "            description = description_elem.get_text(strip=True)\n",
    "\n",
    "            # Create a dictionary with the extracted data for this performance\n",
    "            performance_data = {\n",
    "                \"Month\": month_name,\n",
    "                \"Date and Time\": date_time,\n",
    "                \"Location\": location,\n",
    "                \"Description\": description\n",
    "            }\n",
    "\n",
    "            # Append the data for this performance to the main list\n",
    "            all_data.append(performance_data)\n",
    "\n",
    "    # Create a DataFrame to store all the data\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Print or use the DataFrame as needed\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to fetch the URL:\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a827c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
